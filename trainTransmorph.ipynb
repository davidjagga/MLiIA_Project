{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aeef857-5b7c-4786-b66a-f3e44005b0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pystrum natsort timm ml_collections pytorch_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc48b339-0316-418e-8123-acc09814e7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os, utils, glob, losses\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from data import datasets, trans\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "from models.TransMorph import CONFIGS as CONFIGS_TM\n",
    "import models.TransMorph as TransMorph\n",
    "from pytorch_msssim import SSIM\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, save_dir):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(save_dir+\"logfile.log\", \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a78bae1-71ff-4f6e-95aa-6e7de90e614b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 2\n",
      "     GPU #0: NVIDIA A40\n",
      "     GPU #1: NVIDIA A40\n",
      "Currently using: NVIDIA A40\n",
      "If the GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "GPU_iden = 1\n",
    "GPU_num = torch.cuda.device_count()\n",
    "print('Number of GPU: ' + str(GPU_num))\n",
    "for GPU_idx in range(GPU_num):\n",
    "    GPU_name = torch.cuda.get_device_name(GPU_idx)\n",
    "    print('     GPU #' + str(GPU_idx) + ': ' + GPU_name)\n",
    "torch.cuda.set_device(GPU_iden)\n",
    "GPU_avai = torch.cuda.is_available()\n",
    "print('Currently using: ' + torch.cuda.get_device_name(GPU_iden))\n",
    "print('If the GPU is available? ' + str(GPU_avai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e8c6e8-c6f9-4612-9a98-2c12efd07ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example Path\n",
    "# data_path = \"/home/udz8gm/TransMorph2D/dataset\"\n",
    "\n",
    "# UPDATE training data path to match data path specified in makeData file \n",
    "data_path = \"/path/to/dataset\"\n",
    "train_path = data_path+\"/train/\"\n",
    "val_path = data_path+\"/val/\"\n",
    "test_path = data_path+\"/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be2b86d-2aaa-4ac2-b044-05c1bf7582d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# loss weights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransMorph_ssim_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_diffusion_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weights[\u001b[38;5;241m0\u001b[39m], weights[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiments/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msave_dir):\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiments/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msave_dir)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msave_dir):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# UPDATE model specifics\n",
    "\n",
    "batch_size = 32\n",
    "train_dir = train_path\n",
    "val_dir = test_path\n",
    "weights = [1, 1] # loss weights\n",
    "save_dir = 'TransMorph_ssim_{}_diffusion_{}/'.format(weights[0], weights[1])\n",
    "if not os.path.exists('experiments/'+save_dir):\n",
    "    os.makedirs('experiments/'+save_dir)\n",
    "if not os.path.exists('logs/'+save_dir):\n",
    "    os.makedirs('logs/'+save_dir)\n",
    "sys.stdout = Logger('logs/'+save_dir)\n",
    "lr = 0.0001 # learning rate\n",
    "epoch_start = 0\n",
    "max_epoch = 10 #max traning epoch\n",
    "cont_training = False #if continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "710b5a0f-2ea3-4ac2-a905-1770b057e019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "register_model(\n",
       "  (spatial_trans): SpatialTransformer()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Initialize model\n",
    "'''\n",
    "config = CONFIGS_TM['TransMorph']\n",
    "model = TransMorph.TransMorph(config)\n",
    "model.cuda()\n",
    "\n",
    "'''\n",
    "Initialize spatial transformation function\n",
    "'''\n",
    "reg_model = utils.register_model(config.img_size, 'nearest')\n",
    "reg_model.cuda()\n",
    "reg_model_bilin = utils.register_model(config.img_size, 'bilinear')\n",
    "reg_model_bilin.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c1b0da5-8581-48f5-b9aa-52274b973c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "If continue from previous training\n",
    "'''\n",
    "if cont_training:\n",
    "    epoch_start = 201\n",
    "    model_dir = 'experiments/'+save_dir\n",
    "    updated_lr = round(lr * np.power(1 - (epoch_start) / max_epoch,0.9),8)\n",
    "    best_model = torch.load(model_dir + natsorted(os.listdir(model_dir))[-1])['state_dict']\n",
    "    print('Model: {} loaded!'.format(natsorted(os.listdir(model_dir))[-1]))\n",
    "    model.load_state_dict(best_model)\n",
    "else:\n",
    "    updated_lr = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd76be8-39fe-473c-b50e-b35a2d501a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, MAX_EPOCHES, INIT_LR, power=0.9):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = round(INIT_LR * np.power( 1 - (epoch) / MAX_EPOCHES ,power),8)\n",
    "def comput_fig(img):\n",
    "    img = img.detach().cpu().numpy()[0:16, 0, :, :]\n",
    "    if img.shape[-1] == 3:\n",
    "        img = img.astype(np.uint8)[...,  ::-1]\n",
    "    fig = plt.figure(figsize=(12,12), dpi=180)\n",
    "    for i in range(img.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[i, :, :], cmap='gray')\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def mk_grid_img(grid_step, line_thickness=1, grid_sz=(64, 256, 256)):\n",
    "    grid_img = np.zeros(grid_sz)\n",
    "    for j in range(0, grid_img.shape[1], grid_step):\n",
    "        grid_img[:, j+line_thickness-1, :] = 1\n",
    "    for i in range(0, grid_img.shape[2], grid_step):\n",
    "        grid_img[:, :, i+line_thickness-1] = 1\n",
    "    grid_img = grid_img[:, None, ...]\n",
    "    grid_img = torch.from_numpy(grid_img).cuda()\n",
    "    return grid_img\n",
    "\n",
    "def save_checkpoint(state, save_dir='models', filename='checkpoint.pth.tar', max_model_num=4):\n",
    "    torch.save(state, save_dir+filename)\n",
    "    model_lists = natsorted(glob.glob(save_dir + '*'))\n",
    "    while len(model_lists) > max_model_num:\n",
    "        os.remove(model_lists[0])\n",
    "        model_lists = natsorted(glob.glob(save_dir + '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcb25ce3-5f4c-4878-9d82-aafb7306e9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize training\n",
    "'''\n",
    "train_composed = transforms.Compose([trans.RandomFlip([2]),\n",
    "                                     trans.NumpyType((np.float32, np.float32)),\n",
    "                                     ])\n",
    "train_set = datasets.RaFDDataset(glob.glob(train_dir + '*.pkl'), transforms=train_composed)\n",
    "val_set = datasets.RaFDInferDataset(glob.glob(val_dir + '*.pkl'), transforms=None)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=50, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=updated_lr, weight_decay=0, amsgrad=True)\n",
    "criterion = losses.SSIM_loss(False)\n",
    "ssim = SSIM(data_range=255, size_average=True, channel=1)\n",
    "criterions = [criterion]\n",
    "criterions += [losses.Grad('l2')]\n",
    "best_ncc = 0\n",
    "writer = SummaryWriter(log_dir='logs/'+save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17912a45-76f9-46dd-b7c7-f0262c1590fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epoch_start, max_epoch):\n",
    "    print('Training Starts', epoch)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    loss_all = utils.AverageMeter()\n",
    "    idx = 0\n",
    "    for data in train_loader:\n",
    "        idx += 1\n",
    "        model.train()\n",
    "        adjust_learning_rate(optimizer, epoch, max_epoch, lr)\n",
    "        data = [t.cuda() for t in data]\n",
    "        x = data[0]\n",
    "        y = data[1]\n",
    "        x_in = torch.cat((x,y), dim=1)\n",
    "        output = model(x_in)\n",
    "        loss = 0\n",
    "        loss_vals = []\n",
    "        for n, loss_function in enumerate(criterions):\n",
    "            if n == 0:\n",
    "                curr_loss = loss_function(output[n], y) * weights[n]\n",
    "            else:\n",
    "                curr_loss = loss_function(output[n], y) * weights[n]\n",
    "            loss_vals.append(curr_loss)\n",
    "            loss += curr_loss\n",
    "        loss_all.update(loss.item(), y.numel())\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del x_in\n",
    "        del output\n",
    "        # flip fixed and moving images\n",
    "        loss = 0\n",
    "        x_in = torch.cat((y, x), dim=1)\n",
    "        output = model(x_in)\n",
    "        for n, loss_function in enumerate(criterions):\n",
    "            if n == 0:\n",
    "                curr_loss = loss_function(output[n], x) * weights[n]\n",
    "            else:\n",
    "                curr_loss = loss_function(output[n], x) * weights[n]\n",
    "            loss_vals[n] += curr_loss\n",
    "            loss += curr_loss\n",
    "        loss_all.update(loss.item(), y.numel())\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Iter {} of {} loss {:.4f}, Img Sim: {:.6f}, Reg: {:.6f}'.format(idx, len(train_loader), loss.item(), loss_vals[0].item() / 2, loss_vals[1].item() / 2))\n",
    "\n",
    "    writer.add_scalar('Loss/train', loss_all.avg, epoch)\n",
    "    print('Epoch {} loss {:.4f}'.format(epoch, loss_all.avg))\n",
    "    '''\n",
    "    Validation\n",
    "    '''\n",
    "    eval_ncc = utils.AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            model.eval()\n",
    "            data = [t.cuda() for t in data]\n",
    "            x_rgb = data[0]\n",
    "            y_rgb = data[1]\n",
    "            x = data[2]\n",
    "            y = data[3]\n",
    "\n",
    "            x_in = torch.cat((y, x), dim=1)\n",
    "            output = model(x_in)\n",
    "            ncc = ssim(output[0], x)\n",
    "            eval_ncc.update(ncc.item(), x.numel())\n",
    "\n",
    "            #flip image\n",
    "            x_in = torch.cat((x, y), dim=1)\n",
    "            output = model(x_in)\n",
    "            ncc = ssim(output[0], y)\n",
    "            eval_ncc.update(ncc.item(), y.numel())\n",
    "\n",
    "            grid_img = mk_grid_img(8, 1, (x.shape[0], config.img_size[0], config.img_size[1]))\n",
    "            def_out = []\n",
    "            for idx in range(3):\n",
    "                x_def = reg_model_bilin([x_rgb[..., idx].cuda().float(), output[1].cuda()])\n",
    "                def_out.append(x_def[..., None])\n",
    "            def_out = torch.cat(def_out, dim=-1)\n",
    "            def_grid = reg_model_bilin([grid_img.float(), output[1].cuda()])\n",
    "\n",
    "            print(eval_ncc.avg)\n",
    "    best_ncc = max(eval_ncc.avg, best_ncc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_ncc': best_ncc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, save_dir='experiments/'+save_dir, filename='dsc{:.3f}.pth.tar'.format(eval_ncc.avg))\n",
    "    writer.add_scalar('DSC/validate', eval_ncc.avg, epoch)\n",
    "    plt.switch_backend('agg')\n",
    "    pred_fig = comput_fig(def_out)\n",
    "    grid_fig = comput_fig(def_grid)\n",
    "    x_fig = comput_fig(x_rgb)\n",
    "    tar_fig = comput_fig(y_rgb)\n",
    "    writer.add_figure('Grid', grid_fig, epoch)\n",
    "    plt.close(grid_fig)\n",
    "    writer.add_figure('input', x_fig, epoch)\n",
    "    plt.close(x_fig)\n",
    "    writer.add_figure('ground truth', tar_fig, epoch)\n",
    "    plt.close(tar_fig)\n",
    "    writer.add_figure('prediction', pred_fig, epoch)\n",
    "    plt.close(pred_fig)\n",
    "    loss_all.reset()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfbd3b8f-94f8-4216-9475-b1c760e57266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32107f4a-8770-42b0-aee1-abd4621fa08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
